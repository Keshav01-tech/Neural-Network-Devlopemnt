{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b997d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=256\n",
    "num_layers = 2\n",
    "input_size = 28\n",
    "sequence_length = 28\n",
    "num_class = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_eppochs = 3\n",
    "load_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4d124e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c040019",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0efe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(nn.Module):\n",
    "    def __init__(self, input_size , hidden_size , num_layers,  num_class):\n",
    "        super(BNN , self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layer = num_layers\n",
    "        self.lstm = nn.LSTM(input_size,hidden_size , num_layers , batch_first=True , bidirectional=True )\n",
    "        self.Fc = nn.Linear(hidden_size*2 ,num_class)\n",
    "    def forward(self , x):\n",
    "        ho = torch.zeros(self.num_layer*2 ,x.size(0),self.hidden_size).to(device=device)#hidden state or shoert term memory\n",
    "        co = torch.zeros(self.num_layer*2 ,x.size(0),self.hidden_size).to(device=device)#cell state or long terem memory\n",
    "        out ,_= self.lstm(x ,(ho , co))#output\n",
    "        out = self.Fc(out[: , -1 , :])#last timesout\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb1d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size , hidden_size , num_layers ,num_class):\n",
    "        super(RNN , self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layer = num_layers\n",
    "        self.Rnn = nn.RNN(input_size,hidden_size , num_layers , batch_first=True )\n",
    "        self.Fc = nn.Linear(hidden_size*sequence_length,num_class)\n",
    "    def forward(self , x):\n",
    "        ho = torch.zeros(self.num_layer,x.size(0),self.hidden_size).to(device=device)\n",
    "        out ,_= self.Rnn(x , ho)\n",
    "        out = out.reshape(out.shape[0] , -1)\n",
    "        out = self.Fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0e5927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state , filename = \"my_checkpointt.pth.tar\"):\n",
    "    print(\"=>saving checkpoint\")\n",
    "    torch.save(state , filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705dd1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbee46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = datasets.MNIST(root ='dataset/' , train= True ,transform = transforms.ToTensor() , download=True)\n",
    "train_lader = DataLoader(train_datasets , batch_size= batch_size ,shuffle=True)\n",
    "test_dataset = datasets.MNIST(root ='dataset/' , train= False ,transform = transforms.ToTensor() , download = True)\n",
    "test_dataloader = DataLoader(test_dataset , batch_size=batch_size , shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8aadb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BNN(input_size,hidden_size,num_layers,num_class).to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "305589c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "critision = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165200d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint):\n",
    "    print(\"=>load checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305f666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1fc7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(num_eppochs):\n",
    "    losses = []\n",
    "\n",
    "    if epochs==2:\n",
    "        check_point = {'state_dict':model.state_dict() , 'optimizer dict': optimizer.state_dict()}\n",
    "        save_checkpoint(check_point)\n",
    "    for batch_idx ,(data ,targets) in enumerate(train_lader):\n",
    "        data = data.to(device = device).squeeze(1)\n",
    "        targets = targets.to(device = device)\n",
    "        scores = model(data)\n",
    "        loss = critision(scores,targets)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25116841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader,model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"accuracy for train dataset\")\n",
    "    else:\n",
    "        print(\"accuracy fo test datsets\")\n",
    "    num_correct = 0\n",
    "    num_samples=0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device=device).squeeze(1)\n",
    "            y = y.to(device = device)\n",
    "            scores = model(x)\n",
    "            _,predictions = scores.max(1)\n",
    "            num_correct += (predictions==y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        print(f'got {num_correct}/{num_samples} with accuraccy  {float(num_correct)/float(num_samples)*100:.2f}'\n",
    "        )\n",
    "    model.train()\n",
    "    def load_checkpoint(checkpoint):\n",
    "        print(\"=>load checkpoint\")\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer dict\"])\n",
    "    if load_model:\n",
    "            load_checkpoint(torch.load(\"my_checkpointt.pth.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b489e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for train dataset\n",
      "got 59040/60000 with accuraccy  98.40\n",
      "=>load checkpoint\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_lader , model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafca606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy o test datsets\n",
      "got 9638/10000 with accuraccy  96.38\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(test_dataloader , model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28056d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
